"""
Multi-Model Episode RAG ì‚¬ìš© ì˜ˆì‹œ.
"""

import asyncio
from src.core.config import get_config
from src.database.base import DatabaseManager
from src.embedding.manager import EmbeddingManager
from src.milvus.client import MilvusClient
from src.episode.multi_model_manager import MultiModelEpisodeRAGManager, create_multi_model_config


async def main():
    """ë‹¤ì¤‘ ëª¨ë¸ RAG ì‚¬ìš© ì˜ˆì‹œ."""
    
    # ì„¤ì • ë¡œë“œ
    config = get_config()
    
    # ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    db_manager = DatabaseManager(config.database)
    embedding_manager = EmbeddingManager(config.embedding_providers)
    milvus_client = MilvusClient(config.milvus)
    milvus_client.connect()
    
    # ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì •
    multi_config = create_multi_model_config()
    
    # ë‹¤ì¤‘ ëª¨ë¸ ë§¤ë‹ˆì € ìƒì„±
    multi_manager = MultiModelEpisodeRAGManager(
        database_manager=db_manager,
        embedding_manager=embedding_manager,
        milvus_client=milvus_client,
        config=multi_config
    )
    
    # 1. ëª¨ë“  ëª¨ë¸ì˜ ì»¬ë ‰ì…˜ ì„¤ì •
    print("ğŸ”§ Setting up collections for all models...")
    await multi_manager.setup_collections_for_all_models(drop_existing=True)
    
    # 2. ëª¨ë¸ ì •ë³´ í™•ì¸
    print("\nğŸ“Š Model Information:")
    model_info = multi_manager.get_model_info()
    for model_name, info in model_info.items():
        print(f"  {model_name}:")
        print(f"    Collection: {info['collection_name']}")
        print(f"    Dimension: {info['vector_dimension']}")
        print(f"    Ready: {info['is_collection_ready']}")
    
    # 3. íŠ¹ì • ëª¨ë¸ë¡œ ì†Œì„¤ ì²˜ë¦¬
    novel_id = 1
    print(f"\nğŸ”„ Processing novel {novel_id} with Ollama model...")
    result = await multi_manager.process_novel_with_model(
        novel_id=novel_id,
        model_name="ollama-nomic",
        force_reprocess=True
    )
    print(f"Result: {result.get('episodes_processed', 0)} episodes processed")
    
    # 4. ëª¨ë“  ëª¨ë¸ë¡œ ì†Œì„¤ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
    print(f"\nğŸ”„ Processing novel {novel_id} with ALL models...")
    all_results = await multi_manager.process_novel_with_all_models(
        novel_id=novel_id,
        force_reprocess=True
    )
    
    for model_name, result in all_results.items():
        if "error" in result:
            print(f"  {model_name}: ERROR - {result['error']}")
        else:
            print(f"  {model_name}: {result.get('episodes_processed', 0)} episodes")
    
    # 5. íŠ¹ì • ëª¨ë¸ë¡œ ê²€ìƒ‰
    query = "ì£¼ì¸ê³µì´ ë§ˆë²•ì„ ì‚¬ìš©í•˜ëŠ” ì¥ë©´"
    print(f"\nğŸ” Searching with Ollama model: '{query}'")
    search_result = multi_manager.search_with_model(
        query=query,
        model_name="ollama-nomic",
        limit=5
    )
    print(f"Found {len(search_result.hits)} results")
    
    # 6. ëª¨ë“  ëª¨ë¸ë¡œ ê²€ìƒ‰ ë¹„êµ
    print(f"\nğŸ” Searching with ALL models: '{query}'")
    all_search_results = multi_manager.search_with_all_models(
        query=query,
        limit=3
    )
    
    for model_name, result in all_search_results.items():
        if "error" in result:
            print(f"  {model_name}: ERROR - {result['error']}")
        else:
            print(f"  {model_name}: {len(result.hits)} results, top score: {result.hits[0].score:.4f}")
    
    # 7. ê¸°ë³¸ ëª¨ë¸ ë³€ê²½
    print(f"\nâš™ï¸ Switching default model to OpenAI...")
    multi_manager.switch_default_model("openai-small")
    default_manager = multi_manager.get_default_manager()
    print(f"New default collection: {default_manager.config.collection_name}")


if __name__ == "__main__":
    asyncio.run(main())