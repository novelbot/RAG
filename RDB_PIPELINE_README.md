# RDB to Vector Pipeline

ì´ í”„ë¡œì íŠ¸ëŠ” ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤(RDB)ì—ì„œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ëŠ” ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### âœ… **ì™„ì „ êµ¬í˜„ëœ RDB â†’ Vector íŒŒì´í”„ë¼ì¸**
- RDB ë°ì´í„° ì¶”ì¶œ ë° ë³€í™˜
- ë‹¤ì¤‘ ì„ë² ë”© í”„ë¡œë°”ì´ë” ì§€ì› (OpenAI, Google, Ollama)
- Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
- ë°°ì¹˜ ì²˜ë¦¬ ë° ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

### ğŸ“Š **ì§€ì› ë°ì´í„°ë² ì´ìŠ¤**
- MySQL
- PostgreSQL
- SQLite
- ê¸°íƒ€ SQLAlchemy í˜¸í™˜ ë°ì´í„°ë² ì´ìŠ¤

### ğŸ”§ **CLI ë„êµ¬**
- `rag-cli data ingest` - ë°ì´í„° ìˆ˜ì§‘
- `rag-cli data validate` - ì„¤ì • ê²€ì¦
- `rag-cli data status` - ìƒíƒœ í™•ì¸
- `rag-cli data sync` - ë°ì´í„° ë™ê¸°í™”

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
src/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ rdb_adapter.py          # RDB â†’ Document ë³€í™˜ ì–´ëŒ‘í„°
â”‚   â”œâ”€â”€ rdb_pipeline.py         # í†µí•© RDB ë²¡í„° íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ rdb_config_validator.py # ì„¤ì • ê²€ì¦ ë„êµ¬
â”‚   â””â”€â”€ pipeline.py             # ê¸°ë³¸ ë²¡í„° íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ base.py                 # RDB ì¶”ì¶œ ê¸°ë³¸ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ generic.py              # ë²”ìš© RDB ì¶”ì¶œê¸°
â”‚   â””â”€â”€ factory.py              # ì¶”ì¶œê¸° íŒ©í† ë¦¬
â”œâ”€â”€ cli/commands/
â”‚   â””â”€â”€ data.py                 # CLI ëª…ë ¹ì–´ êµ¬í˜„
â””â”€â”€ ...

examples/
â”œâ”€â”€ rdb_pipeline_usage_example.py  # ì‚¬ìš© ì˜ˆì œ
â””â”€â”€ embedding_usage_example.py     # ì„ë² ë”© ì˜ˆì œ

tests/
â””â”€â”€ test_rdb_pipeline_integration.py  # í†µí•© í…ŒìŠ¤íŠ¸
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
uv sync
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ì— ì¶”ê°€
OPENAI_API_KEY=your_openai_api_key
GOOGLE_API_KEY=your_google_api_key
# ê¸°íƒ€ í•„ìš”í•œ API í‚¤ë“¤
```

### 3. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
application configì—ì„œ RDB ì—°ê²°ì„ ì„¤ì •í•©ë‹ˆë‹¤:

```python
from src.core.config import DatabaseConfig, DatabaseType

rdb_connections = {
    "mysql_db": DatabaseConfig(
        database_type=DatabaseType.MYSQL,
        host="localhost",
        port=3306,
        database="your_database",
        username="your_username",
        password="your_password"
    )
}
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. ì‹œìŠ¤í…œ ê²€ì¦
```bash
# ì „ì²´ ì‹œìŠ¤í…œ ê²€ì¦
rag-cli data validate

# íŠ¹ì • ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦
rag-cli data validate --database mysql_db --detailed
```

### 2. ë°ì´í„° ìˆ˜ì§‘
```bash
# íŒŒì¼ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
rag-cli data ingest --path ./documents --recursive

# ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
rag-cli data ingest --path . --batch-size 100
```

### 3. í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

#### ê¸°ë³¸ ì‚¬ìš©ë²•
```python
import asyncio
from src.pipeline.rdb_pipeline import create_rdb_vector_pipeline
from src.core.config import DatabaseConfig, DatabaseType

async def main():
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    db_config = DatabaseConfig(
        database_type=DatabaseType.MYSQL,
        host="localhost",
        database="your_db",
        username="user",
        password="pass"
    )
    
    # íŒŒì´í”„ë¼ì¸ ìƒì„±
    pipeline = create_rdb_vector_pipeline(
        database_name="my_database",
        database_config=db_config,
        collection_name="documents"
    )
    
    # ë°ì´í„° ì²˜ë¦¬
    result = await pipeline.process_all_tables()
    print(f"Processed {result.successful_documents} documents")
    
    pipeline.close()

asyncio.run(main())
```

#### ê³ ê¸‰ ì„¤ì •
```python
from src.pipeline.rdb_pipeline import RDBVectorPipeline, RDBPipelineConfig
from src.pipeline.rdb_adapter import RDBAdapterConfig
from src.extraction.base import ExtractionMode

# ì»¤ìŠ¤í…€ ì–´ëŒ‘í„° ì„¤ì •
adapter_config = RDBAdapterConfig(
    content_format="json",
    include_table_name=True,
    exclude_null_values=True,
    max_content_length=5000
)

# íŒŒì´í”„ë¼ì¸ ì„¤ì •
pipeline_config = RDBPipelineConfig(
    database_name="my_db",
    database_config=db_config,
    extraction_mode=ExtractionMode.INCREMENTAL,
    adapter_config=adapter_config,
    max_concurrent_tables=5,
    continue_on_table_error=True
)

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
pipeline = RDBVectorPipeline(pipeline_config)
result = await pipeline.process_all_tables()
```

## ğŸ” êµ¬ì„± ìš”ì†Œ

### 1. **RDB ì¶”ì¶œê¸° (RDBExtractor)**
- `BaseRDBExtractor`: ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
- `GenericRDBExtractor`: ë²”ìš© êµ¬í˜„ì²´
- `RDBExtractorFactory`: íŒ©í† ë¦¬ íŒ¨í„´

### 2. **ë¬¸ì„œ ì–´ëŒ‘í„° (RDBDocumentAdapter)**
- RDB í–‰ì„ Document ê°ì²´ë¡œ ë³€í™˜
- ë‹¤ì–‘í•œ ì½˜í…ì¸  í˜•ì‹ ì§€ì› (structured, json, plain)
- ë©”íƒ€ë°ì´í„° ê´€ë¦¬

### 3. **í†µí•© íŒŒì´í”„ë¼ì¸ (RDBVectorPipeline)**
- ì „ì²´ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- ë³‘ë ¬ ì²˜ë¦¬ ë° ë°°ì¹˜ ìµœì í™”
- ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„

### 4. **ì„¤ì • ê²€ì¦ê¸° (RDBConfigValidator)**
- ì‹œìŠ¤í…œ ì„¤ì • ê²€ì¦
- ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
- ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ í™•ì¸

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ì§„í–‰ ìƒí™© ì¶”ì 
```python
# íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸
status = pipeline.get_status()
print(f"Pipeline ID: {status['pipeline_id']}")
print(f"Collection: {status['collection_name']}")

# í—¬ìŠ¤ ì²´í¬
health = await pipeline.health_check()
print(f"Overall Health: {health['overall_status']}")
```

### ê²°ê³¼ ë¶„ì„
```python
result = await pipeline.process_all_tables()

print(f"ì²˜ë¦¬ëœ í…Œì´ë¸”: {result.processed_tables}/{result.total_tables}")
print(f"ì„±ê³µí•œ ë¬¸ì„œ: {result.successful_documents}/{result.total_documents}")
print(f"ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
print(f"ì„±ê³µë¥ : {result.document_success_rate:.1f}%")

# ì—ëŸ¬ ë¶„ì„
for error in result.errors:
    print(f"ì—ëŸ¬: {error}")
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
python test_rdb_pipeline_integration.py
```

### ì‚¬ìš© ì˜ˆì œ ì‹¤í–‰
```bash
python examples/rdb_pipeline_usage_example.py
```

## âš™ï¸ ê³ ê¸‰ ì„¤ì •

### 1. ì¶”ì¶œ ëª¨ë“œ
- `FULL`: ì „ì²´ ë°ì´í„° ì¶”ì¶œ
- `INCREMENTAL`: ì¦ë¶„ ì¶”ì¶œ
- `CUSTOM`: ì»¤ìŠ¤í…€ ì¿¼ë¦¬

### 2. ì½˜í…ì¸  í˜•ì‹
- `structured`: êµ¬ì¡°í™”ëœ í•„ë“œ:ê°’ í˜•ì‹
- `json`: JSON í˜•ì‹
- `plain`: ë‹¨ìˆœ í…ìŠ¤íŠ¸

### 3. ì„±ëŠ¥ ìµœì í™”
- ë°°ì¹˜ í¬ê¸° ì¡°ì •: `batch_size`
- ë™ì‹œ ì²˜ë¦¬: `max_concurrent_tables`
- ë©”ëª¨ë¦¬ ì œí•œ: `max_content_length`

### 4. ì—ëŸ¬ ì²˜ë¦¬
- `continue_on_table_error`: í…Œì´ë¸” ì—ëŸ¬ ì‹œ ê³„ì† ì§„í–‰
- `continue_on_pipeline_error`: íŒŒì´í”„ë¼ì¸ ì—ëŸ¬ ì‹œ ê³„ì† ì§„í–‰
- `max_retries`: ì¬ì‹œë„ íšŸìˆ˜

## ğŸ“ ì˜ˆì œ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì „ììƒê±°ë˜ ë°ì´í„°ë² ì´ìŠ¤
```python
# ì œí’ˆ, ì£¼ë¬¸, ê³ ê° í…Œì´ë¸”ì„ ë²¡í„°í™”
pipeline = create_rdb_vector_pipeline(
    database_name="ecommerce",
    database_config=mysql_config,
    include_tables=["products", "orders", "customers"],
    collection_name="ecommerce_docs"
)
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë¸”ë¡œê·¸ ì½˜í…ì¸ 
```python
# ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì™€ ëŒ“ê¸€ì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
adapter_config = RDBAdapterConfig(
    content_format="json",
    exclude_columns=["id", "created_at"]
)

pipeline = create_rdb_vector_pipeline(
    database_name="blog",
    database_config=postgres_config,
    adapter_config=adapter_config
)
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ê³ ê° ì§€ì› í‹°ì¼“
```python
# ì¦ë¶„ ì²˜ë¦¬ë¡œ ìƒˆë¡œìš´ í‹°ì¼“ë§Œ ì²˜ë¦¬
pipeline_config = RDBPipelineConfig(
    database_name="support",
    database_config=db_config,
    extraction_mode=ExtractionMode.INCREMENTAL,
    incremental_column="updated_at"
)
```

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨**
   ```bash
   rag-cli data validate --database your_db
   ```

2. **ì„ë² ë”© ì„œë¹„ìŠ¤ ì˜¤ë¥˜**
   - API í‚¤ í™•ì¸
   - ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
   - í• ë‹¹ëŸ‰ ì œí•œ í™•ì¸

3. **Milvus ì—°ê²° ë¬¸ì œ**
   - Milvus ì„œë²„ ìƒíƒœ í™•ì¸
   - í¬íŠ¸ ë° í˜¸ìŠ¤íŠ¸ ì„¤ì • í™•ì¸

4. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   - ë™ì‹œ ì²˜ë¦¬ ìˆ˜ ì œí•œ
   - ì½˜í…ì¸  ê¸¸ì´ ì œí•œ

### ë¡œê·¸ í™•ì¸
```bash
# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
tail -f logs/app.log

# íŠ¹ì • ì»´í¬ë„ŒíŠ¸ ë¡œê·¸ í•„í„°ë§
grep "RDBVectorPipeline" logs/app.log
```

## ğŸ”„ ì—…ê·¸ë ˆì´ë“œ ë° ë§ˆì´ê·¸ë ˆì´ì…˜

### ë²„ì „ í˜¸í™˜ì„±
- ê¸°ì¡´ ì¶”ì¶œ ë¡œì§ê³¼ ì™„ì „ í˜¸í™˜
- ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥

### ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
```python
# ê¸°ì¡´ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
old_pipeline = create_rdb_vector_pipeline(
    collection_name="old_documents"
)
new_pipeline = create_rdb_vector_pipeline(
    collection_name="new_documents"
)
```

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### í…ŒìŠ¤íŠ¸ í™˜ê²½
- CPU: 8 cores
- RAM: 16GB
- Database: MySQL 8.0
- Records: 100,000 rows

### ì„±ëŠ¥ ê²°ê³¼
- ì²˜ë¦¬ ì†ë„: ~1,000 documents/minute
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~2GB peak
- ë””ìŠ¤í¬ I/O: ~100MB/minute

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create feature branch
3. Add tests for new functionality
4. Submit pull request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

## ğŸ†˜ ì§€ì›

ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´:
1. GitHub Issuesì— ë“±ë¡
2. ë¬¸ì„œ í™•ì¸
3. ì˜ˆì œ ì½”ë“œ ì°¸ì¡°

---

**RDB to Vector Pipeline**ì„ ì‚¬ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‰