#!/usr/bin/env python3
"""
OpenAI ì„ë² ë”© ëª¨ë¸ì˜ max_tokens ì œí•œ í…ŒìŠ¤íŠ¸
ì‹¤ì œ API í˜¸ì¶œ ì—†ì´ ì„¤ì •ê°’ë§Œ í™•ì¸
"""

import os
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from src.embedding.types import EmbeddingConfig, EmbeddingProvider
from src.embedding.langchain_embeddings import LangChainEmbeddingProvider
from src.embedding.manager import EmbeddingManager, EmbeddingProviderConfig
from src.episode.processor import EpisodeEmbeddingProcessor
from src.database.base import DatabaseManager
from src.core.config import DatabaseConfig, DatabaseType

def test_openai_max_tokens():
    """Test OpenAI embedding models max_tokens configuration"""
    
    print("=" * 80)
    print("OpenAI ì„ë² ë”© ëª¨ë¸ max_tokens ì œí•œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # Test models
    test_models = [
        "text-embedding-ada-002",
        "text-embedding-3-small", 
        "text-embedding-3-large"
    ]
    
    for model in test_models:
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ëª¨ë¸: {model}")
        print("-" * 40)
        
        # Create config for OpenAI
        config = EmbeddingConfig(
            provider=EmbeddingProvider.OPENAI,
            model=model,
            api_key="test-key-not-used"  # ì‹¤ì œ API í˜¸ì¶œ ì•ˆí•¨
        )
        
        try:
            # Create provider (API í˜¸ì¶œ ì—†ì´ ì´ˆê¸°í™”ë§Œ)
            provider = LangChainEmbeddingProvider(config)
            
            # Get model info
            model_info = provider.get_model_info()
            
            print(f"âœ… Provider: {model_info.get('provider')}")
            print(f"âœ… Model: {model_info.get('model')}")
            print(f"âœ… Max Tokens: {model_info.get('max_tokens', 'NOT SET')}")
            print(f"âœ… Dimensions: {model_info.get('dimensions')}")
            
            # Expected values
            expected_max_tokens = 8191
            actual_max_tokens = model_info.get('max_tokens', 0)
            
            if actual_max_tokens == expected_max_tokens:
                print(f"âœ… Max tokens ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë¨: {actual_max_tokens}")
            else:
                print(f"âŒ Max tokens ë¶ˆì¼ì¹˜: ì˜ˆìƒ={expected_max_tokens}, ì‹¤ì œ={actual_max_tokens}")
                
        except Exception as e:
            print(f"âš ï¸  Provider ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ (API í‚¤ ì—†ì–´ì„œ ì •ìƒ): {e}")
            print("   max_tokens í™•ì¸ì„ ìœ„í•´ ì§ì ‘ ì ‘ê·¼...")
            
            # Direct check without provider initialization
            from src.embedding.langchain_embeddings import LangChainEmbeddingProvider
            max_tokens = LangChainEmbeddingProvider.MODEL_MAX_TOKENS.get(model, "NOT FOUND")
            print(f"   ğŸ“ MODEL_MAX_TOKENS['{model}'] = {max_tokens}")
    
    print("\n" + "=" * 80)
    print("ì²­í‚¹ ì„ê³„ê°’ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # Test chunking threshold calculation
    for model, max_tokens in [
        ("text-embedding-ada-002", 8191),
        ("ollama-model", 2048)
    ]:
        threshold = int(max_tokens * 0.85)
        char_limit = int(threshold / 1.5)  # Korean text estimation
        
        print(f"\nğŸ“Š {model}:")
        print(f"   Max Tokens: {max_tokens}")
        print(f"   ì²­í‚¹ ì„ê³„ê°’ (85%): {threshold} tokens")
        print(f"   ë¬¸ì ìˆ˜ ì œí•œ (í•œêµ­ì–´): ~{char_limit} ê¸€ì")
        print(f"   â†’ {char_limit}ì ì´í•˜: ë‹¨ì¼ ì„ë² ë”©")
        print(f"   â†’ {char_limit}ì ì´ˆê³¼: ìë™ ì²­í‚¹")

def test_processor_integration():
    """Test processor's ability to get max_tokens from different providers"""
    
    print("\n" + "=" * 80)
    print("EpisodeProcessorì™€ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # Mock database config
    db_config = DatabaseConfig(
        database_type=DatabaseType.SQLITE,
        database="test.db"
    )
    
    # Create mock database manager
    db_manager = DatabaseManager(db_config)
    
    # Test with OpenAI provider
    openai_config = EmbeddingConfig(
        provider=EmbeddingProvider.OPENAI,
        model="text-embedding-3-small",
        api_key="test-key"
    )
    
    provider_config = EmbeddingProviderConfig(
        provider=EmbeddingProvider.OPENAI,
        config=openai_config
    )
    
    try:
        # Create embedding manager
        embedding_manager = EmbeddingManager([provider_config], enable_cache=False)
        
        # Create processor
        processor = EpisodeEmbeddingProcessor(db_manager, embedding_manager)
        
        # Get max tokens from processor
        max_tokens = processor._get_model_max_tokens()
        
        print(f"\nâœ… Processorê°€ ì¸ì‹í•œ max_tokens: {max_tokens}")
        
        if max_tokens == 8191:
            print("âœ… OpenAI ëª¨ë¸ì˜ max_tokensê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹ë¨!")
        else:
            print(f"âŒ ì˜ˆìƒê°’(8191)ê³¼ ë‹¤ë¦„: {max_tokens}")
            
    except Exception as e:
        print(f"âš ï¸  í†µí•© í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ (API í‚¤ ì—†ì–´ì„œ ì •ìƒ): {e}")

if __name__ == "__main__":
    test_openai_max_tokens()
    test_processor_integration()
    
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)