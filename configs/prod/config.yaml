app_name: "RAG Server"
version: "0.1.0"
environment: "production"
debug: false

database:
  host: "localhost"
  port: 5432
  name: "ragdb"
  user: "postgres"
  password: ""  # Set via DB_PASSWORD environment variable
  driver: "postgresql"
  pool_size: 20
  max_overflow: 30
  pool_timeout: 60

milvus:
  host: "localhost"
  port: 19530
  user: ""
  password: ""
  secure: true
  collection_name: "rag_vectors"
  index_type: "IVF_FLAT"
  metric_type: "IP"
  nlist: 2048

llm:
  provider: "openai"
  model: "gpt-3.5-turbo"
  api_key: ""  # Set via LLM_API_KEY environment variable
  base_url: null
  temperature: 0.7
  max_tokens: 1000

embedding:
  provider: "openai"
  model: "text-embedding-ada-002"
  api_key: ""  # Set via EMBEDDING_API_KEY environment variable
  base_url: null
  dimension: 1536
  batch_size: 100

auth:
  secret_key: ""  # Set via SECRET_KEY environment variable
  algorithm: "HS256"
  access_token_expire_minutes: 30
  refresh_token_expire_days: 7
  enable_rbac: true
  enable_row_level_security: true

api:
  host: "0.0.0.0"
  port: 8000
  workers: 4
  reload: false
  debug: false
  cors_origins: []
  rate_limit: 100

logging:
  level: "INFO"
  format: "{time} | {level} | {message}"
  file_path: "logs/app.log"
  max_size: "50 MB"
  rotation: "daily"
  retention: "30 days"

data_source:
  rdb_connections: {}
  file_paths: []
  sync_interval: 3600
  chunk_size: 1000
  chunk_overlap: 200

rag:
  mode: "single"
  retrieval_k: 5
  similarity_threshold: 0.7
  rerank_enabled: true
  ensemble_models: []