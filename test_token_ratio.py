#!/usr/bin/env python3
"""
í† í° ë¹„ìœ¨ ìˆ˜ì • í™•ì¸ í…ŒìŠ¤íŠ¸
ì‹¤ì œ GPT-4o ê¸°ì¤€: 1,424 characters â†’ 921 tokens
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

def test_token_calculations():
    """í† í° ê³„ì‚° ë¡œì§ í…ŒìŠ¤íŠ¸"""
    
    print("=" * 80)
    print("í•œêµ­ì–´ í…ìŠ¤íŠ¸ í† í° ë¹„ìœ¨ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ì‹¤ì œ GPT-4o ë°ì´í„°
    actual_chars = 1424
    actual_tokens = 921
    actual_ratio = actual_chars / actual_tokens  # ~1.546
    
    print(f"\nğŸ“Š ì‹¤ì œ GPT-4o ë°ì´í„°:")
    print(f"  â€¢ ë¬¸ì ìˆ˜: {actual_chars:,} characters")
    print(f"  â€¢ í† í° ìˆ˜: {actual_tokens:,} tokens")
    print(f"  â€¢ ë¹„ìœ¨: {actual_ratio:.2f} chars/token")
    
    # ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” ë¹„ìœ¨
    our_ratio = 1.55
    print(f"\nğŸ“Š ì ìš©ëœ ë¹„ìœ¨: {our_ratio} chars/token")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        1000,   # ì§§ì€ í…ìŠ¤íŠ¸
        5000,   # ì¤‘ê°„ í…ìŠ¤íŠ¸  
        10000,  # ê¸´ í…ìŠ¤íŠ¸
        15000,  # ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸
    ]
    
    print("\nğŸ“Š ë¬¸ì ìˆ˜ â†’ í† í° ìˆ˜ ë³€í™˜ í…ŒìŠ¤íŠ¸:")
    print("-" * 50)
    print("| ë¬¸ì ìˆ˜ | ì˜ˆìƒ í† í° (1.55) | ì‹¤ì œ ë¹„ìœ¨ í† í° |")
    print("|---------|------------------|----------------|")
    
    for chars in test_cases:
        estimated_tokens_new = int(chars / 1.55)
        estimated_tokens_actual = int(chars / actual_ratio)
        print(f"| {chars:7,} | {estimated_tokens_new:16,} | {estimated_tokens_actual:14,} |")
    
    # OpenAI ëª¨ë¸ì˜ ì²­í‚¹ ì„ê³„ê°’ ê³„ì‚°
    print("\n" + "=" * 80)
    print("OpenAI ëª¨ë¸ ì²­í‚¹ ì„ê³„ê°’ (ìˆ˜ì •ëœ ë¹„ìœ¨)")
    print("=" * 80)
    
    models = [
        ("text-embedding-ada-002", 8191),
        ("text-embedding-3-small", 8191),
        ("text-embedding-3-large", 8191),
    ]
    
    for model_name, max_tokens in models:
        safe_tokens = int(max_tokens * 0.85)  # 85% ì•ˆì „ ë§ˆì§„
        safe_chars = int(safe_tokens * 1.55)  # ìˆ˜ì •ëœ ë¹„ìœ¨
        
        print(f"\nğŸ“Š {model_name}:")
        print(f"  â€¢ Max Tokens: {max_tokens:,}")
        print(f"  â€¢ ì•ˆì „ í† í° (85%): {safe_tokens:,} tokens")
        print(f"  â€¢ ìµœëŒ€ ë¬¸ì ìˆ˜: {safe_chars:,} characters")
        print(f"  â€¢ ì²˜ë¦¬ ë°©ì‹:")
        print(f"    - {safe_chars:,}ì ì´í•˜ â†’ ë‹¨ì¼ ì„ë² ë”©")
        print(f"    - {safe_chars:,}ì ì´ˆê³¼ â†’ ìë™ ì²­í‚¹")
    
    # Ollamaì™€ ë¹„êµ
    print("\n" + "=" * 80)
    print("Ollama vs OpenAI ë¹„êµ (ìˆ˜ì •ëœ ë¹„ìœ¨)")
    print("=" * 80)
    
    ollama_max = 2048
    ollama_safe = int(ollama_max * 0.85)
    ollama_chars = int(ollama_safe * 1.55)
    
    openai_max = 8191
    openai_safe = int(openai_max * 0.85)
    openai_chars = int(openai_safe * 1.55)
    
    print(f"\n| ëª¨ë¸ | ìµœëŒ€ ë¬¸ì ìˆ˜ | ë¹„ê³  |")
    print("|------|-------------|------|")
    print(f"| Ollama  | {ollama_chars:,}ì | ê¸°ë³¸ ëª¨ë¸ |")
    print(f"| OpenAI  | {openai_chars:,}ì | ì•½ {openai_chars/ollama_chars:.1f}ë°° ë” ë§ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬ |")
    
    # ì‹¤ì œ ì—í”¼ì†Œë“œ ì˜ˆì‹œ
    print("\nğŸ“ ì‹¤ì œ ì—í”¼ì†Œë“œ ê¸¸ì´ ì˜ˆì‹œ:")
    print("-" * 50)
    
    episode_examples = [
        ("ì§§ì€ ì—í”¼ì†Œë“œ", 2000),
        ("ë³´í†µ ì—í”¼ì†Œë“œ", 5000),
        ("ê¸´ ì—í”¼ì†Œë“œ", 10000),
        ("ë§¤ìš° ê¸´ ì—í”¼ì†Œë“œ", 15000),
    ]
    
    for desc, char_count in episode_examples:
        tokens = int(char_count / 1.55)
        ollama_chunks = 1 if char_count <= ollama_chars else (char_count // 1500) + 1
        openai_chunks = 1 if char_count <= openai_chars else (char_count // 1500) + 1
        
        print(f"\n{desc} ({char_count:,}ì / {tokens:,} tokens):")
        print(f"  â€¢ Ollama: {ollama_chunks}ê°œ ì²­í¬ë¡œ ì²˜ë¦¬")
        print(f"  â€¢ OpenAI: {openai_chunks}ê°œ ì²­í¬ë¡œ ì²˜ë¦¬")

if __name__ == "__main__":
    test_token_calculations()
    
    print("\n" + "=" * 80)
    print("âœ… í† í° ë¹„ìœ¨ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("   ì´ì „: 1ì â†’ 1.5 í† í° (ì˜ëª»ëœ ê³„ì‚°)")
    print("   í˜„ì¬: 1.55ì â†’ 1 í† í° (ì˜¬ë°”ë¥¸ ê³„ì‚°)")
    print("=" * 80)